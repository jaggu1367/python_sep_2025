{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0191188e-5b79-4ac1-b078-b9a14ece8977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Introduction to `csv` Module\n",
    "The `csv` module in Python is used for reading and writing CSV (Comma Separated Values) files.  \n",
    "It provides flexible classes and functions to handle CSV structured data.\n",
    "\n",
    "**Basic Syntax**\n",
    "```python\n",
    "import csv\n",
    "```\n",
    "\n",
    "CSV files store tabular data in plain text format where values are separated by commas.  \n",
    "The `csv` module supports multiple delimiters, quoting styles, and reading/writing in dictionary form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70c8b309-6189-4fdf-bca1-7348a9fa71fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Import csv Module"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "print(\"csv module imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "397d64d1-33a7-47d9-9953-1e0cd4ff9e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading CSV File using `csv.reader`\n",
    "`csv.reader` reads CSV files row-by-row and returns each row as a list.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "with open(\"file.csv\") as file:\n",
    "    data = csv.reader(file)\n",
    "    for row in data:\n",
    "        print(row)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ff7225c-03f3-4e36-8e37-2e5a07eba432",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Reading CSV using csv.reader"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = \"\"\"id,name,marks\n",
    "1,John,88\n",
    "2,Alice,92\n",
    "3,David,75\n",
    "\"\"\"\n",
    "with open(\"/tmp/students.csv\", \"w\") as f:\n",
    "    f.write(sample_data)\n",
    "\n",
    "with open(\"/tmp/students.csv\", newline=\"\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for row in csv_reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87837804-6b97-4250-afe0-6f362ee24a9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing to CSV using `csv.writer`\n",
    "`csv.writer` is used to write rows to a CSV file one row at a time.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "with open(\"file.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([col1, col2])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7957a95f-37cb-414d-ae91-e43b65b7a4b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Writing CSV using csv.writer"
    }
   },
   "outputs": [],
   "source": [
    "output_file = \"/tmp/marks.csv\"\n",
    "rows = [[\"id\", \"name\", \"score\"],\n",
    "        [1, \"John\", 85],\n",
    "        [2, \"Emily\", 91],\n",
    "        [3, \"Chris\", 78]]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV File Created:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32a1349c-ac79-4330-9cd8-702c45dde5a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Handling Custom Delimiter\n",
    "CSV files may use delimiters like `;`, `|`, `:` instead of commas.\n",
    "Use the `delimiter` argument for such cases.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "csv.reader(file, delimiter=\";\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e157299-6539-4a2e-8dbb-2f35b59d3e24",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Reading CSV with Semicolon Delimiter"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = \"\"\"id;product;price\n",
    "1;Laptop;78000\n",
    "2;Mouse;700\n",
    "3;Keyboard;1500\n",
    "\"\"\"\n",
    "with open(\"/tmp/products.csv\", \"w\") as f:\n",
    "    f.write(sample_data)\n",
    "\n",
    "with open(\"/tmp/products.csv\") as f:\n",
    "    data = csv.reader(f, delimiter=\";\")\n",
    "    for row in data:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c475c87-a2a3-4d40-98ad-c752dbd59820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading CSV Using `csv.DictReader`\n",
    "`csv.DictReader` reads rows as dictionaries using column headers as keys.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "csv.DictReader(file)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03754aae-b67c-4374-839f-5fde16a89825",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Example of csv.DictReader"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/tmp/students.csv\") as f:\n",
    "    dict_reader = csv.DictReader(f)\n",
    "    for row in dict_reader:\n",
    "        print(dict(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8f05e29-465c-49e3-9198-f62c9ee23c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing CSV Using `csv.DictWriter`\n",
    "`csv.DictWriter` writes rows where each row is a dictionary.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "writer = csv.DictWriter(file, fieldnames=[...])\n",
    "writer.writeheader()\n",
    "writer.writerow({...})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e993ea3-a6e2-49ed-bab9-978971388a1e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Example of csv.DictWriter"
    }
   },
   "outputs": [],
   "source": [
    "output_file = \"/tmp/employees.csv\"\n",
    "data = [\n",
    "    {\"emp_id\": 101, \"name\": \"Sam\", \"salary\": 45000},\n",
    "    {\"emp_id\": 102, \"name\": \"Lisa\", \"salary\": 52000},\n",
    "    {\"emp_id\": 103, \"name\": \"Mike\", \"salary\": 61000}\n",
    "]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as f:\n",
    "    fieldnames = [\"emp_id\", \"name\", \"salary\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for entry in data:\n",
    "        writer.writerow(entry)\n",
    "\n",
    "print(\"CSV File Created:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c56e34b8-6e03-409f-a66f-1c4357c3c092",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Handling Quotes and Escape Characters\n",
    "CSV may contain commas within quotes.  \n",
    "Use parameters like `quotechar`, `quoting`, and `escapechar`.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "csv.reader(file, quoting=csv.QUOTE_ALL)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ea0a0a2-34d3-4443-9792-dc39bbb6bb36",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Reading CSV with Quoting"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = '''id,name,comment\n",
    "1,John,\"Excellent performance, keep going\"\n",
    "2,Alice,\"Needs improvement, but dedicated\"\n",
    "'''\n",
    "with open(\"/tmp/feedback.csv\", \"w\") as f:\n",
    "    f.write(sample_data)\n",
    "\n",
    "with open(\"/tmp/feedback.csv\") as f:\n",
    "    reader = csv.reader(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93971a0d-0025-4011-8c1a-3abc79c05232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Skipping Header Row\n",
    "Skip the column header manually using `next(reader)` once.\n",
    "\n",
    "**Syntax**\n",
    "```python\n",
    "reader = csv.reader(file)\n",
    "next(reader)  # skip header\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63171354-0ef3-4b01-8922-89b0ce7b9280",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Skipping Header Example"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/tmp/students.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # header skipped\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a17daff8-81df-4c1c-8185-07895ab95790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "In this notebook, we learned:\n",
    "- Reading & writing CSV\n",
    "- Handling custom delimiters\n",
    "- `DictReader` & `DictWriter`\n",
    "- Managing quotes and escape characters\n",
    "- Skipping headers  \n",
    "The `csv` module is fast, lightweight, and ideal for structured plain-text data processing in Python."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9.16 csv module [theory]",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
